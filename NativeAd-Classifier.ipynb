{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code fits a model to the training HTML data set, and makes predictions on the test data set.\n",
    "# The features are counts of various string occurences in each HTML file. \n",
    "#\n",
    "# Counts of various HTML style indicators are included, inspired by David Schinn's public script.\n",
    "# Counts of words chosen by FeatureSelection_Words.ipynb are also included.\n",
    "#\n",
    "import glob\n",
    "import multiprocessing\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import numpy\n",
    "import pandas as pd\n",
    "#\n",
    "from __future__ import print_function\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#\n",
    "#\n",
    "# The list feature_words contains words chosen by FeatureSelection_Words.\n",
    "feature_words = ['home', 'com', 'end', 'tag', 'contact', 'blog', 'news', 'new','sign', 'content',\n",
    "     'code', 'search', 'email', 'top', 'share', 'twitter','gt', 'site', 'video',\n",
    "     'comments', 'script', 'div', 'footer', 'like', 'free', 'policy', 'one',\n",
    "     'us', 'post', 'business', 'world', 'get', 'time', 'page', 'social', 'start',\n",
    "     'posts', 'help', 'use', 'follow', 'health', 'class', 'best', \n",
    "     'life', 'header', 'ad', 'm', 'e', 'mobile', 'go', 'services']\n",
    "#\n",
    "#\n",
    "# Function which takes input HTML file and counts occurences of various strings.\n",
    "# create_data returns a dictionary values, where key = string, value = count.\n",
    "#\n",
    "def create_data(filepath):\n",
    "    values = {}\n",
    "    filename = os.path.basename(filepath)\n",
    "    with open(filepath, 'rb') as infile:\n",
    "        text = infile.read()\n",
    "    # The following features are named to avoid potential overlap with feature_words    \n",
    "    values['file_name'] = filename\n",
    "    if filename in train_keys:\n",
    "        values['sponsored0'] = train_keys[filename]\n",
    "    else:\n",
    "        values['sponsored0'] = 0 \n",
    "    # Count occurences of various strings relating to HTML style\n",
    "    values['lines0'] = text.count('\\n')\n",
    "    values['spaces0'] = text.count(' ')\n",
    "    values['tabs0'] = text.count('\\t')\n",
    "    values['braces0'] = text.count('{')\n",
    "    values['brackets0'] = text.count('[')\n",
    "    values['words0'] = len(re.split('\\s+', text))\n",
    "    values['length0'] = len(text)\n",
    "    values['hyperlinks0'] = text.count('<a')\n",
    "    values['paragraphs0'] = text.count('<p')\n",
    "    values['divs0'] = text.count('<div')\n",
    "    values['urls0'] = text.count('http:') + text.count('https:') \n",
    "    values['images0'] = text.count('<img')\n",
    "    values['@signs'] = text.count('@')\n",
    "    values['hrefs'] = text.count('href')\n",
    "    values['strong_'] = text.count('<strong')\n",
    "    values['meta_'] = text.count('<meta')\n",
    "    values['dotcom_'] = text.count('.com')\n",
    "    values['link_'] = text.count('<link')\n",
    "    values['script_'] = text.count('<script')\n",
    "    values['function'] = text.count('function')\n",
    "    # Count strings relating to social media\n",
    "    values['facebook_'] = text.count('facebook') + text.count('Facebook')\n",
    "    values['pinterest_'] = text.count('pinterest') + text.count('Pinterest')\n",
    "    values['twitter_'] = text.count('twitter') + text.count('Twitter')\n",
    "    values['instagram_'] = text.count('instagram') + text.count('Instagram')\n",
    "    # Count occurences of numeric strings of the form \" # \", where # ranges from 0 to 25\n",
    "    number_string = [\" \" + str(i) + \" \" for i in range(26)]\n",
    "    values['num_count'] = sum([text.count(item) for item in number_string])\n",
    "    # Count occurences of single letters. Some HTML files have broken text, e.g. \"Hello\" -> \"H e l l o\"\n",
    "    alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', \n",
    "                'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', \n",
    "                'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    alphabet_string = [\" \" + item + \" \" for item in alphabet]\n",
    "    values['letter_count'] = sum([text.count(item) for item in alphabet_string])\n",
    "    # Count occurences of words selected by FeatureSelection_Words (contained in feature_words)\n",
    "    for word in feature_words:\n",
    "        values[word] = text.count(word)\n",
    "    return values\n",
    "#\n",
    "#\n",
    "# Function which computes cross-validation score.\n",
    "# Here we use the leave-P-out method, where P = (1-frac) x size of training data\n",
    "# The model averages predictions from random forest and extremely randomized trees\n",
    "#\n",
    "# Note that the final submission uses n_estimators = 250\n",
    "def cross_val(training_df,frac):\n",
    "#    \n",
    "    train_cv, test_cv = shuffle_and_sample(training_df,frac)            \n",
    "#    \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=1, n_jobs = -1)\n",
    "    rf.fit(train_cv[features], train_cv[\"sponsored0\"])\n",
    "    rf_pred = rf.predict_proba(test_cv[features])[:,1]\n",
    "    del rf\n",
    "#   \n",
    "    et = ExtraTreesClassifier(n_estimators=100, random_state=1, n_jobs = -1)\n",
    "    et.fit(train_cv[features], train_cv[\"sponsored0\"])\n",
    "    et_pred = et.predict_proba(test_cv[features])[:,1]\n",
    "    del et\n",
    "#\n",
    "    test_probs = (rf_pred + et_pred)/2\n",
    "    true_labels = test_cv[\"sponsored0\"].values\n",
    "    aucscore=roc_auc_score(true_labels,test_probs)\n",
    "    return aucscore\n",
    "\n",
    "# Function for sampling training data, used by cross_val\n",
    "def shuffle_and_sample(df,frac):\n",
    "    df = df.reindex(numpy.random.permutation(df.index))\n",
    "    split = int(df.shape[0] * frac)\n",
    "    train = df[:split]\n",
    "    test = df[split:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This code block reads in training HTML data, and counts occurences of strings specified in create_data.\n",
    "# The output is written to TrainingData.csv for posterity.\n",
    "#\n",
    "# Specify input directory containing test data\n",
    "input_dir_train = \"/media/sf_VboxShar/Native_Advertising_train/\"\n",
    "#\n",
    "# Read in labels (sponsored = 1, non-sponsored = 0) for training data\n",
    "train_labels = pd.read_csv(\"/media/sf_VboxShar/train_v2.csv\")\n",
    "train_keys = dict([a[1] for a in train_labels.iterrows()])\n",
    "#\n",
    "#\n",
    "filepaths = glob.glob(input_dir_train + '*.txt')\n",
    "num_tasks = len(filepaths)\n",
    "#\n",
    "p = multiprocessing.Pool()\n",
    "results = p.imap(create_data, filepaths)\n",
    "while (True):\n",
    "    completed = results._index \n",
    "    print(\"\\r--- Reading training HTML files: {:,} out of {:,}\".format(completed, num_tasks), end='')\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(1)\n",
    "    if (completed == num_tasks): break\n",
    "p.close()\n",
    "p.join()\n",
    "#\n",
    "# Write output to TrainingData.csv\n",
    "training_df = pd.DataFrame(list(results))\n",
    "training_df.to_csv(\"TrainingData.csv\", index=False)\n",
    "del training_df\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This code block reads in test HTML data, and counts occurences of strings specified in create_data.\n",
    "# The output is written to TestData.csv for posterity.\n",
    "#\n",
    "# Specify input directory containing test data\n",
    "input_dir_test = \"/media/sf_VboxShar/Native_Advertising_test/\"\n",
    "#\n",
    "filepaths = glob.glob(input_dir_test + '*.txt')\n",
    "num_tasks = len(filepaths)\n",
    "#\n",
    "p = multiprocessing.Pool()\n",
    "results = p.imap(create_data, filepaths)\n",
    "while (True):\n",
    "    completed = results._index \n",
    "    print(\"\\r--- Reading test HTML files {:,} out of {:,}\".format(completed, num_tasks), end='')\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(1)\n",
    "    if (completed == num_tasks): break\n",
    "p.close()\n",
    "p.join()\n",
    "#\n",
    "# Write output to TestData.csv\n",
    "test_df = pd.DataFrame(list(results))\n",
    "test_df.to_csv(\"TestData.csv\", index=False)\n",
    "del test_df\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training and test data from csv files\n",
    "training_df= pd.read_csv(\"TrainingData.csv\")\n",
    "test_df= pd.read_csv(\"TestData.csv\")\n",
    "# Obtain feature list\n",
    "features = list(training_df.columns.values)\n",
    "features.remove(\"sponsored0\")\n",
    "features.remove(\"file_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain cross-validation score, using leave-p-out where p = number of training files x 0.2\n",
    "# \n",
    "aucscores=[cross_val(training_df,0.8) for i in range(10)]\n",
    "mean_aucscore = sum(aucscores)/float(len(aucscores))\n",
    "print(\"AUC score from cross validation: \", mean_aucscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make prediction for final submission, save to NativeAdv.csv\n",
    "# \n",
    "rf = RandomForestClassifier(n_estimators=250, random_state=1, n_jobs = -1)\n",
    "rf.fit(training_df[features], training_df[\"sponsored0\"])\n",
    "rf_pred = rf.predict_proba(test_df[features])[:,1]\n",
    "del rf\n",
    "#   \n",
    "et = ExtraTreesClassifier(n_estimators=250, random_state=1, n_jobs = -1)\n",
    "et.fit(training_df[features], training_df[\"sponsored0\"])\n",
    "et_pred = et.predict_proba(test_df[features])[:,1]\n",
    "del et\n",
    "#\n",
    "predicted = 0.5 * rf_pred + 0.5 * et_pred\n",
    "submission = pd.DataFrame({\"file\": test_df[\"file_name\"], \"sponsored\": predicted})\n",
    "submission.to_csv(\"NativeAdv.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
